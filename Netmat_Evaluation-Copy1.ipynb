{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "from Predictors.ElasticNetTuner import ElasticNetTuner\n",
    "from Predictors.RandomForestTuner import RandomForestTuner\n",
    "from Predictors.NNTuner import NNTuner\n",
=======
    "import Predictors.ElasticNetTuner as EN\n",
    "from Predictors.RandomForestTuner import RandomForestTuner\n",
    "import Predictors.NNTuner  as NN\n",
>>>>>>> 45da129def88b28daad6860e94aecf7d11ba697c
    "from DataLoader.MetadataHelper import *\n",
    "from DataLoader.utils import load_netmats\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 2,
=======
   "execution_count": 90,
>>>>>>> 45da129def88b28daad6860e94aecf7d11ba697c
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "(460,)\n"
=======
      "(460, 1)\n"
>>>>>>> 45da129def88b28daad6860e94aecf7d11ba697c
     ]
    }
   ],
   "source": [
    "#Load netmats and meta data\n",
    "metadata = load_patient_metadata('Data/joint_HCP_500_metadata.csv', subject_measures=[\"Gender\"])\n",
<<<<<<< HEAD
    "metadata = metadata.as_matrix()\n",
    "metadata = np.ravel(metadata)\n",
    "print metadata.shape\n",
    "le = LabelEncoder()\n",
    "metadata = le.fit_transform(metadata)\n",
    "netmats = load_netmats('/home/tadlington/bitbucket/HCP_500/HCP500_netmat460.txt')"
=======
    "\n",
    "\n",
    "#metadata = metadata.as_matrix()\n",
    "#metadata = np.ravel(metadata)\n",
    "\n",
    "print metadata.shape\n",
    "le = LabelEncoder()\n",
    "metadata = le.fit_transform(metadata[\"Gender\"].values)\n",
    "\n",
    "\n",
    "netmats = load_netmats('/home/tadlington/bitbucket/HCP_500/HCP500_460_partial_corr_netmat.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Gender]\n",
      "Index: []\n",
      "(0, 1)\n"
     ]
    }
   ],
   "source": [
    "subject_ids = [100307,100408,101107,101309,101915,103111,103414,\n",
    "                            103818,105014,105115,106016,108828,110411,111312,\n",
    "                            111716,113619,113922,114419,115320,116524,117122,\n",
    "                            118528,118730,118932,120111,122317,122620,123117,\n",
    "                            123925,124422,125525,126325,127630,127933,128127,\n",
    "                            128632,129028,130013,130316,131217,131722,133019,\n",
    "                            133928,135225,135932,136833,138534,139637,140925,\n",
    "                            144832,146432,147737,148335,148840,149337,149539,\n",
    "                            149741,151223,151526,151627,153025,154734,156637,159340,160123,161731,162733,163129,176542,178950,\n",
    "                            188347,189450,190031,192540,196750,198451,199655,\n",
    "                            201111,208226,211417,211720,212318,214423,221319,\n",
    "                            239944,245333,280739,298051,366446,397760,414229,\n",
    "                            499566,654754,672756,751348,756055,792564,856766,\n",
    "                            857263,899885]\n",
    "metadata = load_patient_metadata('../unrestricted_sofira_11_17_2015_6_15_1.csv', subject_measures=[\"Gender\"], subjects=subject_ids)\n",
    "print metadata.shape\n",
    "le = LabelEncoder()\n",
    "metadata = le.fit_transform(metadata[\"Gender\"].values)\n",
    "netmats = load_netmats('/home/tadlington/fNETMATS/netmats-ridgereg-nozstat.txt')"
>>>>>>> 45da129def88b28daad6860e94aecf7d11ba697c
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 7,
=======
   "execution_count": 4,
>>>>>>> 45da129def88b28daad6860e94aecf7d11ba697c
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "classifier\n",
      "classifier\n",
      "TODO fix lower limit for _gen_fine-intervals\n"
=======
      "(460, 1)\n"
>>>>>>> 45da129def88b28daad6860e94aecf7d11ba697c
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
    "#Create your Tuner\n",
    "\n",
    "tuner = RandomForestTuner(njobs=-1, cv=5, classifier=True)\n",
    "#\n",
    "tuner.fit(netmats, metadata)\n"
=======
    "subject_ids = [100307, 100408, 101006, 101107, 101309, 101915, 102008, 102311, 102816, 103111, 103414, 103515, 103818, 104820, 105014, 105115, 105216, 106016, 106319, 106521, 107321, 107422, 108121, 108323, 108525, 108828, 109123, 109325, 110411, 111312, 111413, 111716, 113215, 113619, 113922, 114419, 114924, 115320, 116524, 117122, 117324, 118528, 118730, 118932, 120111, 120212, 120515, 121618, 122317, 122620, 123117, 123420, 123925, 124220, 124422, 124826, 125525, 126325, 126628, 127630, 127933, 128127, 128632, 129028, 130013, 130316, 130922, 131217, 131722, 131924, 132118, 133019, 133625, 133827, 133928, 134324, 135225, 135528, 135932, 136227, 136833, 137027, 137128, 137633, 137936, 138231, 138534, 139233, 139637, 140117, 140824, 140925, 141422, 141826, 142626, 142828, 143325, 144226, 144832, 145834, 146331, 146432, 147030, 147737, 148032, 148335, 148840, 148941, 149337, 149539, 149741, 150625, 150726, 151223, 151526, 151627, 151728, 152831, 153025, 153429, 154431, 154734, 154936, 155635, 156233, 156637, 157336, 157437, 158035, 158136, 158540, 159138, 159239, 159340, 159441, 160123, 160830, 161327, 161630, 161731, 162026, 162228, 162329, 162733, 163129, 163331, 163432, 163836, 164030, 164131, 164939, 165032, 165840, 166438, 167036, 167743, 168139, 168341, 169444, 171633, 172029, 172130, 172332, 172534, 172938, 173334, 173435, 173536, 173940, 175035, 175439, 176542, 177645, 177746, 178142, 178748, 178849, 178950, 179346, 180129, 180432, 180836, 180937, 181131, 181232, 182739, 182840, 183034, 185139, 186141, 187143, 187547, 187850, 188347, 189349, 189450, 190031, 191033, 191336, 191437, 191841, 192439, 192540, 192843, 193239, 194140, 194645, 194847, 195041, 195647, 195849, 196144, 196750, 197348, 197550, 198350, 198451, 198855, 199150, 199251, 199453, 199655, 199958, 200109, 200614, 201111, 201414, 201818, 203418, 204016, 204521, 205119, 205220, 205725, 205826, 208024, 208226, 208327, 209834, 209935, 210011, 210415, 210617, 211215, 211316, 211417, 211720, 211922, 212116, 212217, 212318, 212419, 214019, 214221, 214423, 214726, 217126, 217429, 221319, 224022, 231928, 233326, 239944, 245333, 246133, 249947, 250427, 250932, 251833, 255639, 256540, 268850, 280739, 285345, 285446, 289555, 290136, 293748, 298051, 298455, 303119, 303624, 307127, 308331, 310621, 316633, 329440, 334635, 339847, 352132, 352738, 356948, 361941, 365343, 366042, 366446, 371843, 377451, 380036, 382242, 386250, 395958, 397154, 397760, 397861, 412528, 414229, 415837, 422632, 433839, 436239, 436845, 441939, 445543, 448347, 465852, 475855, 480141, 485757, 486759, 497865, 499566, 500222, 510326, 519950, 522434, 530635, 531536, 540436, 541943, 545345, 547046, 552544, 559053, 561242, 562446, 565452, 566454, 567052, 567961, 568963, 570243, 573249, 573451, 579665, 580044, 580347, 581349, 583858, 585862, 586460, 592455, 594156, 598568, 599469, 599671, 601127, 613538, 620434, 622236, 623844, 627549, 638049, 645551, 654754, 665254, 672756, 673455, 677968, 679568, 680957, 683256, 685058, 687163, 690152, 695768, 702133, 704238, 705341, 709551, 713239, 715041, 715647, 729254, 729557, 732243, 734045, 742549, 748258, 748662, 749361, 751348, 753251, 756055, 759869, 761957, 765056, 770352, 771354, 779370, 782561, 784565, 788876, 789373, 792564, 792766, 802844, 814649, 816653, 826353, 826454, 833148, 833249, 837560, 837964, 845458, 849971, 856766, 857263, 859671, 861456, 865363, 871762, 872158, 872764, 877168, 877269, 885975, 887373, 889579, 894673, 896778, 896879, 898176, 899885, 901038, 901139, 901442, 904044, 907656, 910241, 912447, 917255, 922854, 930449, 932554, 937160, 951457, 957974, 958976, 959574, 965367, 965771, 978578, 979984, 983773, 984472, 987983, 991267, 992774, 994273]\n",
    "metadata = load_patient_metadata('../unrestricted_ta2812_5_29_2016_4_58_52.csv', subject_measures=[\"PicVocab_AgeAdj\"], subjects=subject_ids)\n",
    "print metadata.shape\n",
    "le = LabelEncoder()\n",
    "metadata = le.fit_transform(metadata[\"PicVocab_AgeAdj\"].values)\n",
    "netmats = load_netmats('/vol/bitbucket/ta2812/Data/HCP_netmats/netmats/netmat2.txt')\n",
    "netmats = np.delete(netmats, 94, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Create your Tuner\n",
    "reload(EN)\n",
    "\n",
    "tuner = RandomForestTuner(n_jobs=-1, cv=5)\n",
    "#tuner = EN.ElasticNetTuner(n_jobs=-1, cv =5)\n",
    "\n",
    "#tuner = EN.NNTuner(n_jobs=-1, cv=5, classifier=True)\n",
    "#tuner.fit(netmats, metadata)\n",
    "#\n",
    "\n"
>>>>>>> 45da129def88b28daad6860e94aecf7d11ba697c
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 12,
=======
   "execution_count": 69,
>>>>>>> 45da129def88b28daad6860e94aecf7d11ba697c
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "0.6\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
      "            max_depth=None, max_features=13, max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=128, n_jobs=1,\n",
      "            oob_score=False, random_state=30, verbose=0, warm_start=False)\n",
      "271\n",
      "0.589130434783\n"
=======
      "(100, 18769)\n",
      "<bound method ElasticNet.decision_function of ElasticNet(alpha=0.1, copy_X=True, fit_intercept=True, l1_ratio=0.7,\n",
      "      max_iter=1000, normalize=False, positive=False, precompute=False,\n",
      "      random_state=None, selection='cyclic', tol=0.0001, warm_start=False)>\n",
      "0\n",
      "0.0\n"
>>>>>>> 45da129def88b28daad6860e94aecf7d11ba697c
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
    "print tuner.grid.best_score_\n",
    "print tuner.forest\n",
    "print sum(metadata == 0)\n",
    "print 271 / 460.0"
=======
    "\"\"\"\n",
    "print tuner.grid.best_score_\n",
    "print tuner.grid.best_params_\n",
    "print tuner.grid.grid_scores_\n",
    "print tuner.forest\n",
    "print sum(metadata == 0)\n",
    "print 271 / 460.0\n",
    "\"\"\"\n",
    "#print tuner.fitted\n",
    "#print tuner.net.mse_path_.shape\n",
    "#print tuner.net.alpha_\n",
    "#print tuner.net.l1_ratio_\n",
    "\n",
    "from sklearn.linear_model import ElasticNet\n",
    "n = ElasticNet(alpha=0.1, l1_ratio=0.7)\n",
    "print netmats.shape\n",
    "n.fit(netmats, metadata)\n",
    "print n.decision_function\n",
    "print np.count_nonzero(n.coef_)\n",
    "print sum(n.coef_)\n",
    "#print sum(tuner.net.coef_)\n"
>>>>>>> 45da129def88b28daad6860e94aecf7d11ba697c
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 4,
=======
   "execution_count": null,
>>>>>>> 45da129def88b28daad6860e94aecf7d11ba697c
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "classifier\n",
      "classifier\n",
      "TODO fix lower limit for _gen_fine-intervals\n",
      "predict\n",
      "classifier\n",
      "classifier\n",
      "TODO fix lower limit for _gen_fine-intervals\n",
      "predict\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  6.1min finished\n"
     ]
=======
      "TODO fix lower limit for _gen_fine-intervals\n",
      "predict\n"
     ]
>>>>>>> 45da129def88b28daad6860e94aecf7d11ba697c
    }
   ],
   "source": [
    "#Get Predictions or score\n",
    "from sklearn.cross_validation import cross_val_predict\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "\n",
<<<<<<< HEAD
    "predictions = cross_val_predict(tuner, netmats, y=metadata, cv=5, verbose=3)"
=======
    "predictions = cross_val_predict(tuner, netmats, y=metadata, cv=10, verbose=2)"
>>>>>>> 45da129def88b28daad6860e94aecf7d11ba697c
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 6,
=======
   "execution_count": 12,
>>>>>>> 45da129def88b28daad6860e94aecf7d11ba697c
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(460,)\n",
<<<<<<< HEAD
      "0.576086956522\n"
=======
      "[ 0.37846201  1.05953865  0.26904348  1.14103907  0.77877245  0.05872872\n",
      "  0.67099686  0.34563076  0.38151895  0.73444805  0.01265237 -0.04485173\n",
      " -0.05771768  0.37996472  0.26182661  0.83428223  0.94947806  0.3042136\n",
      "  0.6470811   0.70368278  0.30313635  0.45238043  0.21982701  0.2736895\n",
      "  1.01248146  1.15445563  1.16975866  1.05896236  0.76878514 -0.21793983\n",
      "  0.3028794   0.06741899 -0.02834669  0.26325579  0.99404932  0.89936025\n",
      "  0.59776548 -0.15003584  0.94962714  0.13729772 -0.35136101  0.26390866\n",
      "  1.16457868  0.40993981  0.31247075  0.14817942  0.17606885  0.90457314\n",
      "  0.83828358  0.68432407  0.48931016 -0.15169294  0.39646302  1.10788852\n",
      " -0.23568353  0.25499321  0.15059445  0.11590623  0.74158437  0.26678666\n",
      "  1.06459761  0.07098967  0.13499853  0.20725711  0.62921089  0.48345869\n",
      "  0.08703653  0.34255761 -0.04344118  0.66663268  0.2098721   0.01098822\n",
      "  0.28203398  0.67454495  0.65460489  0.41328265  0.44445982  0.06901354\n",
      "  0.12057682  0.51314813  0.3326206   0.75747163 -0.33433552  0.49817579\n",
      "  0.69928835  0.32622469  0.39153751  0.21871673  0.50146335 -0.18132428\n",
      "  1.03055678  0.28208425  0.13500245  0.48980188  1.30599376  0.41334916\n",
      " -0.04479402  0.63925078  0.27066069  0.40313172  0.90342442  0.57284541\n",
      " -0.40074259  0.26692462  0.28839549  0.07500431  0.48654239  0.72794492\n",
      "  0.83386225  0.65947711  0.86959969  0.99821053  0.21519302  0.39437753\n",
      "  0.28119663  0.9264888   0.66263961  0.34941472  0.96436579  0.03673629\n",
      "  1.05778727  0.79310577  0.29518612  0.60378105  0.83900842 -0.02624709\n",
      " -0.07450081 -0.25691296  0.47992613  1.1145713   1.10339715  0.24724703\n",
      "  1.06587228  0.20754374  0.77218715  0.49212476  0.49295405  0.46314468\n",
      "  0.10693162 -0.00307297  0.76501262  0.06737439  0.41274675  0.57437959\n",
      "  0.5965926  -0.1483622   0.47645193  0.90033742  0.46608961  0.06457647\n",
      "  0.94220035  0.62535265  0.67945722  0.01671906  0.30806581  1.20643195\n",
      "  0.62204748 -0.21057112  0.90013898  1.0631933   0.88048155  0.09858374\n",
      " -0.0627634  -0.03570269  0.87453509  0.46727787  0.06174602 -0.43129988\n",
      "  0.44728045 -0.26185149 -0.25883585  0.08132557  0.09208796  0.20031423\n",
      "  0.63002245  0.9826053   0.94726894  0.0392162   0.13996184 -0.29417857\n",
      " -0.08064936  1.07354953  0.48993513 -0.17617712  0.42090752  0.48574258\n",
      "  0.97970816 -0.18004978  0.22928617  0.89392321  0.11154605  1.02010142\n",
      "  0.46177579 -0.30612809  1.42332358  0.24013424  0.158266    1.10989861\n",
      " -0.10194791  0.31286907 -0.36080006 -0.17640568  0.7721609   0.09458661\n",
      " -0.39980652  0.46687956 -0.02125664  0.07439372  0.19134587  1.18303091\n",
      "  0.3486039   0.01682699  0.33315547  0.06797291  0.98037044  0.73774949\n",
      "  0.60688943  0.33072752 -0.39222484  0.53636756  1.06192899  0.77372374\n",
      "  0.08903189  0.33843313  0.5406545   0.54521096 -0.40833884  0.71489142\n",
      "  0.30362816 -0.11948395  0.82379361  0.28774168  0.32571853  1.04233731\n",
      "  0.12126792 -0.05272493  0.79006296  0.36824269  0.80948358  0.93153696\n",
      " -0.21171929  0.04801643  0.97806184  0.21673356  0.66606749  0.86510192\n",
      "  0.13828826  1.12538351  0.15058502 -0.14843678  0.28757327  0.16401542\n",
      " -0.03987367  0.83861692  0.39613424  0.77645559 -0.11824163 -0.04489544\n",
      "  0.29870383  0.23794039  0.9649379   0.04553171 -0.26744159 -0.1832074\n",
      "  0.1303182   0.14709599  0.23383846  1.00328604  0.25265694  0.23893348\n",
      "  0.31983629  0.05875939  0.12353664  0.91102176  0.24049026  0.29859125\n",
      "  0.20062216  0.23156742  0.70400835  0.21055677  1.21536756  0.23292062\n",
      "  0.74407958 -0.23640672  0.21308719  0.41548817  0.34187316  0.14046031\n",
      "  0.7404492   0.60997882  0.16712824  0.69051214  0.13711504  0.29566778\n",
      "  0.82434969  0.44175057  0.26874107  0.86546897  0.37937497  1.35875536\n",
      "  1.03129575  0.11131848  0.59993672  0.75560304 -0.08143823  1.09141035\n",
      "  0.43460821  0.05476985  0.69347253  0.19350636  0.11195389 -0.15488424\n",
      "  0.71956835  0.87474539  0.30449477  0.20527288  0.66540149 -0.0999275\n",
      "  0.81375834  0.75508104 -0.01659322 -0.70839467 -0.16348536  0.44457548\n",
      " -0.24665633  0.79703014  0.95588251  0.86294707  0.21706173  0.5851694\n",
      "  0.33205927 -0.26702395  0.43916751  0.29584017  0.66828012  0.3510203\n",
      " -0.04053221  0.73518335  0.14675196  0.19469239  0.24439023  0.64706643\n",
      "  0.64805197  0.37856291  0.40070978  0.1823682   0.58529961  1.08801852\n",
      "  0.06418887 -0.1946103   0.87818547  0.77076696  0.55782466  0.2018512\n",
      "  0.65743905  0.89604591  0.15735625  0.12410212  0.64526459  0.55446133\n",
      "  0.29661182  0.00243828  0.25258207 -0.06418013  0.23428028  0.80305089\n",
      "  0.34453595  0.21422472 -0.05820953  0.18458969  0.0884772   0.94732845\n",
      "  0.82037734  1.05929355  0.48816569  0.51192426  0.60509797  0.70748176\n",
      "  0.02424456  0.22962635  0.09238859 -0.0396178   0.62118604  0.02951553\n",
      "  0.0892986   0.34462202  0.75835164  0.16327356  0.02255198 -0.09477557\n",
      "  0.67953616  1.20682919  0.50214469  0.8032371   0.34520612  1.17235966\n",
      " -0.06193537  0.14105638  0.28559088  0.29780853  0.14872119  0.55412854\n",
      "  0.87976626  0.19802535  0.90495464  0.44914648  0.63177196  0.35589864\n",
      "  0.03560386  0.33071026  0.81314706 -0.01661239  0.1937576   0.19557922\n",
      "  0.02172316  0.98602186  0.47823532  0.66937388  0.31462151  0.33245172\n",
      "  1.15830943  0.59545201  0.20391762  0.39303425  0.11256215  0.47535558\n",
      "  0.11792258 -0.14920195  0.7569219  -0.005401    0.09980549  0.85914395\n",
      "  0.71678591 -0.08984275  1.05795143 -0.09813248  0.21869274  0.03438149\n",
      " -0.31653168  1.03182924  0.74121653  0.90257533  0.8836328  -0.02824046\n",
      "  0.55443866  0.88364131  0.357131   -0.04486723  1.05617951  0.06703973\n",
      "  0.95279243  0.3363744   0.36407672  0.13207009  0.49218169  0.24661532\n",
      " -0.39983331  0.94080381  0.59175566  0.95751023]\n",
      "[ 0.  1.  0.  1.  1.  0.  1.  0.  0.  1.  0. -0. -0.  0.  0.  1.  1.  0.\n",
      "  1.  1.  0.  0.  0.  0.  1.  1.  1.  1.  1. -0.  0.  0. -0.  0.  1.  1.\n",
      "  1. -0.  1.  0. -0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  0. -0.  0.  1.\n",
      " -0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  1.  0.  0.  0. -0.  1.  0.  0.\n",
      "  0.  1.  1.  0.  0.  0.  0.  1.  0.  1. -0.  0.  1.  0.  0.  0.  1. -0.\n",
      "  1.  0.  0.  0.  1.  0. -0.  1.  0.  0.  1.  1. -0.  0.  0.  0.  0.  1.\n",
      "  1.  1.  1.  1.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  0.  1.  1. -0.\n",
      " -0. -0.  0.  1.  1.  0.  1.  0.  1.  0.  0.  0.  0. -0.  1.  0.  0.  1.\n",
      "  1. -0.  0.  1.  0.  0.  1.  1.  1.  0.  0.  1.  1. -0.  1.  1.  1.  0.\n",
      " -0. -0.  1.  0.  0. -0.  0. -0. -0.  0.  0.  0.  1.  1.  1.  0.  0. -0.\n",
      " -0.  1.  0. -0.  0.  0.  1. -0.  0.  1.  0.  1.  0. -0.  1.  0.  0.  1.\n",
      " -0.  0. -0. -0.  1.  0. -0.  0. -0.  0.  0.  1.  0.  0.  0.  0.  1.  1.\n",
      "  1.  0. -0.  1.  1.  1.  0.  0.  1.  1. -0.  1.  0. -0.  1.  0.  0.  1.\n",
      "  0. -0.  1.  0.  1.  1. -0.  0.  1.  0.  1.  1.  0.  1.  0. -0.  0.  0.\n",
      " -0.  1.  0.  1. -0. -0.  0.  0.  1.  0. -0. -0.  0.  0.  0.  1.  0.  0.\n",
      "  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  1.  0.  1. -0.  0.  0.  0.  0.\n",
      "  1.  1.  0.  1.  0.  0.  1.  0.  0.  1.  0.  1.  1.  0.  1.  1. -0.  1.\n",
      "  0.  0.  1.  0.  0. -0.  1.  1.  0.  0.  1. -0.  1.  1. -0. -1. -0.  0.\n",
      " -0.  1.  1.  1.  0.  1.  0. -0.  0.  0.  1.  0. -0.  1.  0.  0.  0.  1.\n",
      "  1.  0.  0.  0.  1.  1.  0. -0.  1.  1.  1.  0.  1.  1.  0.  0.  1.  1.\n",
      "  0.  0.  0. -0.  0.  1.  0.  0. -0.  0.  0.  1.  1.  1.  0.  1.  1.  1.\n",
      "  0.  0.  0. -0.  1.  0.  0.  0.  1.  0.  0. -0.  1.  1.  1.  1.  0.  1.\n",
      " -0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  0.  0.  0.  1. -0.  0.  0.\n",
      "  0.  1.  0.  1.  0.  0.  1.  1.  0.  0.  0.  0.  0. -0.  1. -0.  0.  1.\n",
      "  1. -0.  1. -0.  0.  0. -0.  1.  1.  1.  1. -0.  1.  1.  0. -0.  1.  0.\n",
      "  1.  0.  0.  0.  0.  0. -0.  1.  1.  1.]\n",
      "[0 1 0 1 1 0 1 0 0 1 0 0 0 0 0 1 1 0 1 0 0 1 0 0 1 1 1 1 1 0 0 0 0 0 1 1 1\n",
      " 0 1 0 0 0 1 1 0 0 0 1 1 1 1 0 0 1 0 0 0 0 1 0 1 0 0 1 1 0 0 0 0 1 0 0 1 1\n",
      " 1 1 0 0 0 1 1 1 0 0 1 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 1 1 1 1 1\n",
      " 1 0 1 0 1 1 0 1 0 1 1 0 0 1 0 0 0 1 1 1 0 1 0 1 0 0 0 0 0 1 0 0 1 1 0 0 1\n",
      " 1 0 1 1 1 0 0 1 1 0 1 1 1 0 0 0 1 0 0 0 1 0 0 0 0 0 1 1 1 0 0 0 0 1 0 0 0\n",
      " 1 1 0 1 1 0 1 0 0 1 0 0 1 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 1 1 1 0 0 1 1 1\n",
      " 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 1 1 0 0 1 0 1 1 0 1 0 0 0 0 0 1 1 1 0 0 0\n",
      " 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 1 0 1 0 0 1 0 0 1 1 0 1 0 0 1 0\n",
      " 0 1 0 1 1 0 1 1 0 1 0 0 1 0 0 0 1 1 0 0 0 0 1 1 0 0 0 0 0 1 1 1 0 1 0 0 0\n",
      " 0 0 0 0 1 0 0 0 1 1 0 0 0 1 1 0 0 1 1 1 0 1 1 0 0 1 1 0 0 0 0 0 1 0 0 0 0\n",
      " 0 1 1 1 1 0 1 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 0 1 0 0 0 0 0 0 1 0 1 0 1\n",
      " 0 0 0 1 0 1 0 0 1 0 1 0 0 1 1 0 0 0 0 0 0 1 0 0 1 1 0 1 0 0 0 0 1 1 1 1 0\n",
      " 1 1 0 0 1 0 1 1 0 0 1 0 0 1 1 1]\n",
      "0.928260869565\n"
>>>>>>> 45da129def88b28daad6860e94aecf7d11ba697c
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print metadata.shape\n",
    "#print metadata\n",
    "#print predictions\n",
<<<<<<< HEAD
    "print accuracy_score(predictions, metadata)\n"
=======
    "rp = np.round(predictions)\n",
    "print metadata\n",
    "print accuracy_score(rp, metadata)\n"
>>>>>>> 45da129def88b28daad6860e94aecf7d11ba697c
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
<<<<<<< HEAD
   "version": "2.7.11+"
=======
   "version": "2.7.6"
>>>>>>> 45da129def88b28daad6860e94aecf7d11ba697c
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
